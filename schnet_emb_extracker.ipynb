{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-10T14:39:15.208196Z",
     "iopub.status.busy": "2025-08-10T14:39:15.207946Z",
     "iopub.status.idle": "2025-08-10T14:39:20.956742Z",
     "shell.execute_reply": "2025-08-10T14:39:20.956205Z",
     "shell.execute_reply.started": "2025-08-10T14:39:15.208171Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ====== 1. Cell: Data Loading and Settings ======\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# CSV file path (band_gap column is removed to prevent data leakage/overfitting)\n",
    "csv_path = \"/kaggle/input/features/modelde_kullanlan_Data.csv\"\n",
    "\n",
    "# CIF directory path (extracted from zip, already loaded as input)\n",
    "cif_dir = \"/kaggle/input/cif-zip/cif_indirme\"\n",
    "\n",
    "# Load the CSV\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Drop band_gap column if it exists (to prevent overfitting during feature engineering)\n",
    "if \"band_gap\" in df.columns:\n",
    "    df = df.drop(columns=[\"band_gap\"])\n",
    "\n",
    "print(f\"✅ Total {len(df)} rows loaded from CSV.\")\n",
    "print(f\"✅ CIF files: {len(os.listdir(cif_dir))} found.\")\n",
    "\n",
    "# Save for future cells\n",
    "df.to_csv(\"/kaggle/working/material_no_target.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-10T14:39:20.957832Z",
     "iopub.status.busy": "2025-08-10T14:39:20.957556Z",
     "iopub.status.idle": "2025-08-10T14:47:27.367457Z",
     "shell.execute_reply": "2025-08-10T14:47:27.366887Z",
     "shell.execute_reply.started": "2025-08-10T14:39:20.957807Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directory containing CIF files\n",
    "cif_dir = \"/kaggle/input/cif-zip/cif_indirme\"\n",
    "\n",
    "# Load the original dataframe\n",
    "df = pd.read_csv(\"/kaggle/working/material_no_target.csv\")\n",
    "\n",
    "valid_indices = []\n",
    "for idx in range(len(df)):\n",
    "    material_id = df.iloc[idx][\"material_id\"]\n",
    "    cif_path = os.path.join(cif_dir, f\"{material_id}.cif\")\n",
    "    # Check if the CIF file exists for the given material_id\n",
    "    if os.path.exists(cif_path):\n",
    "        valid_indices.append(idx)\n",
    "\n",
    "print(f\"✅ Number of entries with valid CIF files: {len(valid_indices)}\")\n",
    "\n",
    "# Create filtered dataframe\n",
    "df_filtered = df.iloc[valid_indices].reset_index(drop=True)\n",
    "\n",
    "# Save the filtered dataframe to disk\n",
    "df_filtered.to_csv(\"/kaggle/working/material_no_target_filtered.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-10T14:47:27.369440Z",
     "iopub.status.busy": "2025-08-10T14:47:27.369237Z",
     "iopub.status.idle": "2025-08-10T15:14:57.924536Z",
     "shell.execute_reply": "2025-08-10T15:14:57.923440Z",
     "shell.execute_reply.started": "2025-08-10T14:47:27.369424Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # Suppress all warnings\n",
    "\n",
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from pymatgen.core import Structure\n",
    "import os\n",
    "import pandas as pd\n",
    "from torch_geometric.nn import SchNet\n",
    "import torch_geometric.data\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# CIF directory path\n",
    "cif_dir = \"/kaggle/input/cif-zip/cif_indirme\"\n",
    "\n",
    "# Load the filtered dataframe\n",
    "df_filtered = pd.read_csv(\"/kaggle/working/material_no_target_filtered.csv\")\n",
    "\n",
    "class CrystalDataset(Dataset):\n",
    "    def __init__(self, dataframe, cif_dir):\n",
    "        super().__init__()\n",
    "        self.df = dataframe\n",
    "        self.cif_dir = cif_dir\n",
    "        self.structures = []\n",
    "        print(\"Pre-loading CIF files... (this may take a while)\")\n",
    "        for idx in range(len(self.df)):\n",
    "            material_id = self.df.iloc[idx][\"material_id\"]\n",
    "            cif_path = os.path.join(self.cif_dir, f\"{material_id}.cif\")\n",
    "            structure = Structure.from_file(cif_path)\n",
    "            self.structures.append(structure)\n",
    "        print(\"CIF files loaded successfully.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        structure = self.structures[idx]\n",
    "        # Atomic numbers (z) and Cartesian coordinates (pos)\n",
    "        z = torch.tensor([site.specie.number for site in structure.sites], dtype=torch.long)\n",
    "        pos = torch.tensor(structure.cart_coords, dtype=torch.float)\n",
    "        data = torch_geometric.data.Data(z=z, pos=pos)\n",
    "        return data\n",
    "\n",
    "dataset = CrystalDataset(df_filtered, cif_dir)\n",
    "loader = DataLoader(dataset, batch_size=16, shuffle=True, num_workers=0)\n",
    "\n",
    "# Initialize SchNet model\n",
    "model = SchNet(hidden_channels=128, num_filters=128, num_interactions=6,\n",
    "               num_gaussians=50, cutoff=10.0, readout=\"add\").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(3):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        # Placeholder for real target values (replace with actual labels)\n",
    "        target = torch.rand(batch.num_graphs).to(device) \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        pred = model(batch).view(-1)\n",
    "        loss = loss_fn(pred, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1} - Loss: {total_loss/len(loader):.4f}\")\n",
    "\n",
    "# Inference\n",
    "model.eval()\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        pred = model(batch).view(-1)\n",
    "        predictions.extend(pred.cpu().tolist())\n",
    "\n",
    "print(f\"Total predictions: {len(predictions)} - DataFrame rows: {len(df_filtered)}\")\n",
    "\n",
    "# Save results\n",
    "df_filtered[\"predicted_band_gap\"] = predictions\n",
    "df_filtered.to_csv(\"/kaggle/working/band_gap_predictions.csv\", index=False)\n",
    "print(\"Predictions saved to: /kaggle/working/band_gap_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-10T15:21:21.112880Z",
     "iopub.status.busy": "2025-08-10T15:21:21.112559Z",
     "iopub.status.idle": "2025-08-10T15:25:18.561606Z",
     "shell.execute_reply": "2025-08-10T15:25:18.560692Z",
     "shell.execute_reply.started": "2025-08-10T15:21:21.112857Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Updated DataLoader with performance optimizations\n",
    "loader = DataLoader(\n",
    "    dataset, \n",
    "    batch_size=32, \n",
    "    shuffle=True, \n",
    "    num_workers=2, \n",
    "    pin_memory=True  # Faster data transfer to GPU\n",
    ")\n",
    "\n",
    "# SchNet Architecture Configuration\n",
    "model = SchNet(\n",
    "    hidden_channels=128, \n",
    "    num_filters=128, \n",
    "    num_interactions=6,\n",
    "    num_gaussians=50, \n",
    "    cutoff=10.0, \n",
    "    readout=\"add\"\n",
    ").to(device)\n",
    "\n",
    "# Using a standard learning rate for Adam\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(3):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        \n",
    "        # Placeholder for target labels\n",
    "        target = torch.rand(batch.num_graphs, device=device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass: providing atomic numbers, positions, and batch index\n",
    "        pred = model(z=batch.z, pos=batch.pos, batch=batch.batch).view(-1)\n",
    "        \n",
    "        loss = loss_fn(pred, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f\"Epoch {epoch+1} - Loss: {total_loss/len(loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-10T15:30:05.050662Z",
     "iopub.status.busy": "2025-08-10T15:30:05.049818Z",
     "iopub.status.idle": "2025-08-10T15:30:51.180615Z",
     "shell.execute_reply": "2025-08-10T15:30:51.179786Z",
     "shell.execute_reply.started": "2025-08-10T15:30:05.050631Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "# Disable gradient calculation for faster inference and lower memory usage\n",
    "with torch.no_grad():\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        # Forward pass using atomic numbers, positions, and batch mapping\n",
    "        pred = model(z=batch.z, pos=batch.pos, batch=batch.batch).view(-1)\n",
    "        predictions.extend(pred.cpu().tolist())\n",
    "\n",
    "print(f\"Total predictions: {len(predictions)} - Filtered DataFrame rows: {len(df_filtered)}\")\n",
    "\n",
    "# Add predictions to the dataframe\n",
    "df_filtered[\"predicted_band_gap\"] = predictions\n",
    "\n",
    "# Save the final results to a CSV file\n",
    "output_path = \"/kaggle/working/band_gap_predictions.csv\"\n",
    "df_filtered.to_csv(output_path, index=False)\n",
    "print(f\"Predictions successfully saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-10T15:36:03.235595Z",
     "iopub.status.busy": "2025-08-10T15:36:03.235273Z",
     "iopub.status.idle": "2025-08-10T15:36:05.712023Z",
     "shell.execute_reply": "2025-08-10T15:36:05.711354Z",
     "shell.execute_reply.started": "2025-08-10T15:36:03.235571Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to the main dataset\n",
    "main_csv_path = \"/kaggle/input/features/modelde_kullanlan_Data.csv\"\n",
    "main_df = pd.read_csv(main_csv_path)\n",
    "\n",
    "# Path to the prediction results\n",
    "pred_csv_path = \"/kaggle/working/band_gap_predictions.csv\"\n",
    "pred_df = pd.read_csv(pred_csv_path)\n",
    "\n",
    "# Merging: Join based on 'material_id'\n",
    "merged_df = main_df.merge(\n",
    "    pred_df[['material_id', 'predicted_band_gap']],  # Select only required columns\n",
    "    on='material_id',\n",
    "    how='left'  # Keep all rows from the main dataset\n",
    ")\n",
    "\n",
    "# Export the combined data\n",
    "output_path = \"/kaggle/working/main_with_predictions.csv\"\n",
    "merged_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"✅ New CSV saved successfully: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-10T15:42:14.754069Z",
     "iopub.status.busy": "2025-08-10T15:42:14.753762Z",
     "iopub.status.idle": "2025-08-10T15:42:17.602729Z",
     "shell.execute_reply": "2025-08-10T15:42:17.601965Z",
     "shell.execute_reply.started": "2025-08-10T15:42:14.754046Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the merged prediction results\n",
    "df = pd.read_csv(\"/kaggle/working/main_with_predictions.csv\")\n",
    "\n",
    "# Select the 'predicted_band_gap' column\n",
    "bandgaps = df['predicted_band_gap']\n",
    "\n",
    "# Count zero values (potential metals)\n",
    "zero_count = (bandgaps == 0).sum()\n",
    "total_count = len(bandgaps)\n",
    "zero_ratio = zero_count / total_count * 100\n",
    "\n",
    "print(f\"Total samples: {total_count}\")\n",
    "print(f\"Zero band gap count: {zero_count} ({zero_ratio:.2f}%)\")\n",
    "\n",
    "# Basic statistics\n",
    "print(\"\\nBand gap summary statistics:\")\n",
    "print(bandgaps.describe())\n",
    "\n",
    "# Histogram and KDE plot\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(bandgaps, bins=50, kde=True, color=\"blue\")\n",
    "plt.title(\"Distribution of Band Gap Predictions\")\n",
    "plt.xlabel(\"Band Gap (eV)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(True)\n",
    "plt.savefig(\"band_gap_distribution.png\") # Standard practice to save in Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-10T15:42:51.047316Z",
     "iopub.status.busy": "2025-08-10T15:42:51.047042Z",
     "iopub.status.idle": "2025-08-10T15:42:52.023899Z",
     "shell.execute_reply": "2025-08-10T15:42:52.023220Z",
     "shell.execute_reply.started": "2025-08-10T15:42:51.047296Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the data file\n",
    "# Note: Ensure the path points to your main dataset or your prediction output\n",
    "df = pd.read_csv(\"/kaggle/input/features/modelde_kullanlan_Data.csv\")\n",
    "\n",
    "# Targeted column for analysis\n",
    "bandgaps = df['band_gap']\n",
    "\n",
    "# Calculate the number of zero values (often representing metallic behavior)\n",
    "zero_count = (bandgaps == 0).sum()\n",
    "total_count = len(bandgaps)\n",
    "zero_ratio = (zero_count / total_count) * 100\n",
    "\n",
    "print(f\"Total number of samples: {total_count}\")\n",
    "print(f\"Zero band gap count: {zero_count} ({zero_ratio:.2f}%)\")\n",
    "\n",
    "# Descriptive statistics\n",
    "print(\"\\nBand gap descriptive statistics:\")\n",
    "print(bandgaps.describe())\n",
    "\n",
    "# Distribution Plot (Histogram + Kernel Density Estimate)\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(bandgaps, bins=50, kde=True, color=\"blue\")\n",
    "plt.title(\"Distribution of Band Gap Values\")\n",
    "plt.xlabel(\"Band Gap (eV)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-10T15:49:07.137746Z",
     "iopub.status.busy": "2025-08-10T15:49:07.137199Z",
     "iopub.status.idle": "2025-08-10T15:49:07.741282Z",
     "shell.execute_reply": "2025-08-10T15:49:07.740587Z",
     "shell.execute_reply.started": "2025-08-10T15:49:07.137721Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Main CSV file containing all original columns\n",
    "df_main = pd.read_csv(\"/kaggle/input/features/modelde_kullanlan_Data.csv\")\n",
    "\n",
    "# CSV file containing the model predictions\n",
    "df_pred = pd.read_csv(\"/kaggle/working/main_with_predictions.csv\")\n",
    "\n",
    "# Extract only the ground truth and predicted band gap columns for comparison\n",
    "df_compare = df_pred[['material_id', 'band_gap', 'predicted_band_gap']].copy()\n",
    "\n",
    "# Drop rows with NaN values in either of these columns to ensure a clean analysis\n",
    "df_compare_clean = df_compare.dropna(subset=['band_gap', 'predicted_band_gap'])\n",
    "\n",
    "print(f\"Number of rows used for analysis: {len(df_compare_clean)}\")\n",
    "\n",
    "y_true = df_compare_clean['band_gap']\n",
    "y_pred = df_compare_clean['predicted_band_gap']\n",
    "\n",
    "# Calculate regression metrics\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "print(f\"MAE: {mae:.4f}\")   # Mean Absolute Error\n",
    "print(f\"MSE: {mse:.4f}\")   # Mean Squared Error\n",
    "print(f\"RMSE: {rmse:.4f}\") # Root Mean Squared Error\n",
    "print(f\"R² Score: {r2:.4f}\") # Coefficient of Determination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-10T15:50:07.198546Z",
     "iopub.status.busy": "2025-08-10T15:50:07.198265Z",
     "iopub.status.idle": "2025-08-10T15:50:07.216050Z",
     "shell.execute_reply": "2025-08-10T15:50:07.215366Z",
     "shell.execute_reply.started": "2025-08-10T15:50:07.198528Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Ground truth band gap range (Original Data):\")\n",
    "print(y_true.describe())\n",
    "\n",
    "print(\"\\nPredicted band gap range (Model Output):\")\n",
    "print(y_pred.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-10T15:50:31.831018Z",
     "iopub.status.busy": "2025-08-10T15:50:31.830396Z",
     "iopub.status.idle": "2025-08-10T15:50:32.284868Z",
     "shell.execute_reply": "2025-08-10T15:50:32.284004Z",
     "shell.execute_reply.started": "2025-08-10T15:50:31.830991Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "# Scatter plot of actual vs predicted values\n",
    "sns.scatterplot(x=y_true, y=y_pred, alpha=0.3)\n",
    "\n",
    "# Labeling with units (eV)\n",
    "plt.xlabel(\"Actual Band Gap (eV)\")\n",
    "plt.ylabel(\"Predicted Band Gap (eV)\")\n",
    "plt.title(\"Actual vs. Predicted Band Gap Distribution\")\n",
    "\n",
    "# 45-degree reference line (Ideal Case)\n",
    "plt.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--')\n",
    "\n",
    "# Save the plot\n",
    "plt.grid(True)\n",
    "plt.savefig(\"parity_plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-10T15:53:15.981202Z",
     "iopub.status.busy": "2025-08-10T15:53:15.980933Z",
     "iopub.status.idle": "2025-08-10T15:53:15.987754Z",
     "shell.execute_reply": "2025-08-10T15:53:15.987189Z",
     "shell.execute_reply.started": "2025-08-10T15:53:15.981182Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Constrain predicted values between 0 and the maximum observed ground truth value\n",
    "y_pred_clipped = np.clip(y_pred, 0, y_true.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-10T15:53:23.469501Z",
     "iopub.status.busy": "2025-08-10T15:53:23.469232Z",
     "iopub.status.idle": "2025-08-10T15:53:23.478908Z",
     "shell.execute_reply": "2025-08-10T15:53:23.478245Z",
     "shell.execute_reply.started": "2025-08-10T15:53:23.469482Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Recalculate metrics using clipped predictions\n",
    "mae = mean_absolute_error(y_true, y_pred_clipped)\n",
    "mse = mean_squared_error(y_true, y_pred_clipped)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_true, y_pred_clipped)\n",
    "\n",
    "print(f\"MAE (after clipping): {mae:.4f}\")\n",
    "print(f\"MSE (after clipping): {mse:.4f}\")\n",
    "print(f\"RMSE (after clipping): {rmse:.4f}\")\n",
    "print(f\"R² (after clipping): {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-10T16:31:03.526401Z",
     "iopub.status.busy": "2025-08-10T16:31:03.526048Z",
     "iopub.status.idle": "2025-08-10T16:31:03.824051Z",
     "shell.execute_reply": "2025-08-10T16:31:03.823435Z",
     "shell.execute_reply.started": "2025-08-10T16:31:03.526380Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load the training data from the specified path\n",
    "df_train = pd.read_csv(\"/kaggle/input/features/modelde_kullanlan_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-10T16:33:06.820513Z",
     "iopub.status.busy": "2025-08-10T16:33:06.819881Z",
     "iopub.status.idle": "2025-08-10T16:48:57.954559Z",
     "shell.execute_reply": "2025-08-10T16:48:57.953825Z",
     "shell.execute_reply.started": "2025-08-10T16:33:06.820491Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch_geometric.data\n",
    "\n",
    "# Load the original CSV containing the ground truth band_gap values\n",
    "df_bandgap = pd.read_csv(\"/kaggle/input/features/modelde_kullanlan_Data.csv\")\n",
    "\n",
    "# Create a mapping dictionary for quick lookup: material_id -> band_gap\n",
    "material_to_bandgap = dict(zip(df_bandgap[\"material_id\"], df_bandgap[\"band_gap\"]))\n",
    "\n",
    "def add_targets_to_dataset(dataset):\n",
    "    \"\"\"Function to verify all materials in the dataset have a target value.\"\"\"\n",
    "    for idx in range(len(dataset.df)):\n",
    "        material_id = dataset.df.iloc[idx][\"material_id\"]\n",
    "        band_gap = material_to_bandgap.get(material_id, None)\n",
    "        if band_gap is None:\n",
    "            raise ValueError(f\"Band gap value not found for: {material_id}\")\n",
    "    print(\"Band gap values successfully mapped.\")\n",
    "\n",
    "# Subclassing CrystalDataset to include the target variable 'y'\n",
    "class CrystalDatasetWithTarget(CrystalDataset):\n",
    "    def __getitem__(self, idx):\n",
    "        # Access the structure pre-loaded in the parent class\n",
    "        structure = self.structures[idx]\n",
    "        \n",
    "        # Atomic numbers and Cartesian coordinates\n",
    "        z = torch.tensor([site.specie.number for site in structure.sites], dtype=torch.long)\n",
    "        pos = torch.tensor(structure.cart_coords, dtype=torch.float)\n",
    "        \n",
    "        # Initialize the PyG Data object\n",
    "        data = torch_geometric.data.Data(z=z, pos=pos)\n",
    "        \n",
    "        # Retrieve and assign the actual band_gap target\n",
    "        material_id = self.df.iloc[idx][\"material_id\"]\n",
    "        band_gap = material_to_bandgap.get(material_id, None)\n",
    "        \n",
    "        if band_gap is None:\n",
    "            raise ValueError(f\"Band gap value not found for material: {material_id}\")\n",
    "            \n",
    "        # Target 'y' must be a tensor for PyTorch Geometric models\n",
    "        data.y = torch.tensor(band_gap, dtype=torch.float)\n",
    "        \n",
    "        return data\n",
    "\n",
    "# Initialize the new dataset with targets\n",
    "dataset_with_target = CrystalDatasetWithTarget(df_filtered, cif_dir)\n",
    "\n",
    "# Create the DataLoader\n",
    "# Note: Batch size and workers can be adjusted based on your hardware\n",
    "loader = DataLoader(dataset_with_target, batch_size=16, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-10T16:54:13.398039Z",
     "iopub.status.busy": "2025-08-10T16:54:13.397772Z",
     "iopub.status.idle": "2025-08-10T17:02:00.455896Z",
     "shell.execute_reply": "2025-08-10T17:02:00.454774Z",
     "shell.execute_reply.started": "2025-08-10T16:54:13.398023Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize SchNet model\n",
    "model = SchNet(\n",
    "    hidden_channels=128, \n",
    "    num_filters=128, \n",
    "    num_interactions=6,\n",
    "    num_gaussians=50, \n",
    "    cutoff=10.0, \n",
    "    readout=\"add\"\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# Training Loop\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass: Passing atomic numbers (z) and positions (pos)\n",
    "        pred = model(batch.z, batch.pos).view(-1)\n",
    "        \n",
    "        # Calculate loss using ground truth (batch.y)\n",
    "        loss = loss_fn(pred, batch.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(loader)\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# Evaluation and Data Collection\n",
    "model.eval()\n",
    "predictions = []\n",
    "true_values = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        pred = model(batch.z, batch.pos).view(-1)\n",
    "        \n",
    "        # Move data to CPU and convert to list for storage\n",
    "        predictions.extend(pred.cpu().tolist())\n",
    "        true_values.extend(batch.y.cpu().tolist())\n",
    "\n",
    "print(f\"Total Predictions: {len(predictions)} - Total Ground Truths: {len(true_values)}\")\n",
    "\n",
    "# Merge results with the filtered dataframe and save to CSV\n",
    "df_filtered[\"predicted_band_gap\"] = predictions\n",
    "df_filtered[\"true_band_gap\"] = true_values\n",
    "\n",
    "output_file = \"/kaggle/working/band_gap_predictions_with_true.csv\"\n",
    "df_filtered.to_csv(output_file, index=False)\n",
    "print(f\"Results saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-10T17:18:17.904034Z",
     "iopub.status.busy": "2025-08-10T17:18:17.903765Z",
     "iopub.status.idle": "2025-08-10T17:18:17.910370Z",
     "shell.execute_reply": "2025-08-10T17:18:17.909638Z",
     "shell.execute_reply.started": "2025-08-10T17:18:17.904014Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CrystalDataset(Dataset):\n",
    "    def __init__(self, dataframe, cif_dir):\n",
    "        super().__init__()\n",
    "        self.df = dataframe\n",
    "        self.cif_dir = cif_dir\n",
    "        self.structures = []\n",
    "        \n",
    "        # Pre-loading CIF structures to memory for faster training access\n",
    "        print(\"Pre-loading CIF files... (this may take a while)\")\n",
    "        for idx in range(len(self.df)):\n",
    "            material_id = self.df.iloc[idx][\"material_id\"]\n",
    "            cif_path = os.path.join(self.cif_dir, f\"{material_id}.cif\")\n",
    "            structure = Structure.from_file(cif_path)\n",
    "            self.structures.append(structure)\n",
    "        print(\"CIF files loaded successfully.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the total number of samples\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Retrieve the pre-loaded pymatgen structure\n",
    "        structure = self.structures[idx]\n",
    "        \n",
    "        # Extract atomic numbers (z) and Cartesian coordinates (pos)\n",
    "        z = torch.tensor([site.specie.number for site in structure.sites], dtype=torch.long)\n",
    "        pos = torch.tensor(structure.cart_coords, dtype=torch.float)\n",
    "        \n",
    "        # Create a PyTorch Geometric Data object\n",
    "        data = torch_geometric.data.Data(z=z, pos=pos)\n",
    "        \n",
    "        # Convert band_gap target value to a tensor and assign to data.y\n",
    "        target = torch.tensor(self.df.iloc[idx][\"band_gap\"], dtype=torch.float)\n",
    "        data.y = target\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-10T17:18:26.901205Z",
     "iopub.status.busy": "2025-08-10T17:18:26.900959Z",
     "iopub.status.idle": "2025-08-10T17:26:09.005328Z",
     "shell.execute_reply": "2025-08-10T17:26:09.004287Z",
     "shell.execute_reply.started": "2025-08-10T17:18:26.901189Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# Device configuration (GPU if available, otherwise CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize SchNet model with specific hyperparameters for crystal structures\n",
    "model = SchNet(\n",
    "    hidden_channels=128, \n",
    "    num_filters=128, \n",
    "    num_interactions=6,\n",
    "    num_gaussians=50, \n",
    "    cutoff=10.0, \n",
    "    readout=\"add\"\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# Training loop\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass: using atomic numbers (z) and 3D positions (pos)\n",
    "        pred = model(batch.z, batch.pos).view(-1)\n",
    "        \n",
    "        # Calculate Mean Squared Error against true values\n",
    "        loss = loss_fn(pred, batch.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    avg_loss = total_loss / len(loader)\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Training Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# Model Evaluation Phase\n",
    "model.eval()\n",
    "predictions = []\n",
    "true_values = []\n",
    "\n",
    "# Disable gradient calculation for efficiency during inference\n",
    "with torch.no_grad():\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        pred = model(batch.z, batch.pos).view(-1)\n",
    "        \n",
    "        # Collect results back to CPU\n",
    "        predictions.extend(pred.cpu().tolist())\n",
    "        true_values.extend(batch.y.cpu().tolist())\n",
    "\n",
    "print(f\"Total predictions: {len(predictions)} - Total ground truth values: {len(true_values)}\")\n",
    "\n",
    "# Append results to the filtered dataframe\n",
    "df_filtered[\"predicted_band_gap\"] = predictions\n",
    "df_filtered[\"true_band_gap\"] = true_values\n",
    "\n",
    "# Save comparison results to a CSV file\n",
    "output_path = \"/kaggle/working/band_gap_predictions_with_true.csv\"\n",
    "df_filtered.to_csv(output_path, index=False)\n",
    "print(f\"Results successfully saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-10T17:33:10.182682Z",
     "iopub.status.busy": "2025-08-10T17:33:10.181931Z",
     "iopub.status.idle": "2025-08-10T17:33:10.186833Z",
     "shell.execute_reply": "2025-08-10T17:33:10.186039Z",
     "shell.execute_reply.started": "2025-08-10T17:33:10.182655Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Verify the total number of samples in the dataset and the loader\n",
    "print(f\"Dataset length: {len(dataset)}\")\n",
    "print(f\"Total samples in Loader: {len(loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-10T17:36:48.146005Z",
     "iopub.status.busy": "2025-08-10T17:36:48.145439Z",
     "iopub.status.idle": "2025-08-10T17:38:04.743088Z",
     "shell.execute_reply": "2025-08-10T17:38:04.742084Z",
     "shell.execute_reply.started": "2025-08-10T17:36:48.145979Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Re-initializing loader for inference (Shuffle is False to maintain order)\n",
    "loader = DataLoader(dataset_with_target, batch_size=16, shuffle=False, num_workers=0)\n",
    "\n",
    "model.eval()\n",
    "predictions = []\n",
    "true_values = []\n",
    "\n",
    "# Gradient calculation is disabled for faster and more memory-efficient inference\n",
    "with torch.no_grad():\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        # Forward pass: providing atomic numbers and positions\n",
    "        pred = model(batch.z, batch.pos).view(-1)\n",
    "        \n",
    "        # Collect results and move to CPU\n",
    "        predictions.extend(pred.cpu().tolist())\n",
    "        true_values.extend(batch.y.cpu().tolist())\n",
    "\n",
    "print(f\"Total predictions: {len(predictions)} - Total ground truth values: {len(true_values)}\")\n",
    "print(f\"Dataset length: {len(dataset_with_target)}\")\n",
    "\n",
    "# Append predictions and actual values to the dataframe\n",
    "import pandas as pd\n",
    "df_filtered[\"predicted_band_gap\"] = predictions\n",
    "df_filtered[\"true_band_gap\"] = true_values\n",
    "\n",
    "# Save to CSV for analysis\n",
    "output_csv = \"/kaggle/working/band_gap_predictions_with_true.csv\"\n",
    "df_filtered.to_csv(output_csv, index=False)\n",
    "print(f\"Predictions and ground truths saved to: {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-10T17:39:03.879270Z",
     "iopub.status.busy": "2025-08-10T17:39:03.878969Z",
     "iopub.status.idle": "2025-08-10T17:47:04.488468Z",
     "shell.execute_reply": "2025-08-10T17:47:04.487564Z",
     "shell.execute_reply.started": "2025-08-10T17:39:03.879247Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Ensure Dataset and DataLoader are loaded correctly\n",
    "print(f\"Dataset length: {len(dataset_with_target)}\")  # Target: 123,634\n",
    "loader = DataLoader(dataset_with_target, batch_size=16, shuffle=False, num_workers=0)\n",
    "print(f\"Loader sample count: {len(loader.dataset)}\")  # Should match dataset length\n",
    "\n",
    "# Model and Optimizer Definition\n",
    "# Using SchNet for continuous property prediction (regression)\n",
    "model = SchNet(\n",
    "    hidden_channels=128, \n",
    "    num_filters=128, \n",
    "    num_interactions=6,\n",
    "    num_gaussians=50, \n",
    "    cutoff=10.0, \n",
    "    readout=\"add\"\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# Training (If loss returns 'nan', verify your input data/scaling)\n",
    "for epoch in range(3):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass: predicted band gaps\n",
    "        pred = model(batch.z, batch.pos).view(-1)\n",
    "        \n",
    "        # Calculate loss against ground truth\n",
    "        loss = loss_fn(pred, batch.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f\"Epoch {epoch+1}/3 - Average Loss: {total_loss/len(loader):.4f}\")\n",
    "\n",
    "# Inference Phase (Setting shuffle=False is critical for data alignment)\n",
    "model.eval()\n",
    "predictions = []\n",
    "true_values = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        pred = model(batch.z, batch.pos).view(-1)\n",
    "        \n",
    "        # Collect values for final dataframe construction\n",
    "        predictions.extend(pred.cpu().tolist())\n",
    "        true_values.extend(batch.y.cpu().tolist())\n",
    "\n",
    "print(f\"Total Predictions: {len(predictions)} - Total True Values: {len(true_values)}\")\n",
    "\n",
    "# Data Integrity Checks\n",
    "# Ensuring output counts perfectly match the input dataset\n",
    "assert len(predictions) == len(dataset_with_target), \"Prediction count mismatch!\"\n",
    "assert len(true_values) == len(dataset_with_target), \"Ground truth count mismatch!\"\n",
    "\n",
    "# Store results back to the dataframe\n",
    "df_filtered[\"predicted_band_gap\"] = predictions\n",
    "df_filtered[\"true_band_gap\"] = true_values\n",
    "\n",
    "# Export the results\n",
    "output_path = \"/kaggle/working/band_gap_predictions_with_true.csv\"\n",
    "df_filtered.to_csv(output_path, index=False)\n",
    "print(f\"✅ Predictions and true values successfully saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-10T17:50:42.026465Z",
     "iopub.status.busy": "2025-08-10T17:50:42.026170Z",
     "iopub.status.idle": "2025-08-10T17:56:45.114327Z",
     "shell.execute_reply": "2025-08-10T17:56:45.113492Z",
     "shell.execute_reply.started": "2025-08-10T17:50:42.026445Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "# 1. Cleaning Problematic Data\n",
    "def clean_dataset(dataset):\n",
    "    \"\"\"Removes data points with NaN/Inf values or invalid atomic numbers.\"\"\"\n",
    "    clean_indices = []\n",
    "    problematic_count = 0\n",
    "    \n",
    "    print(\"Cleaning dataset...\")\n",
    "    for i in range(len(dataset)):\n",
    "        try:\n",
    "            data = dataset[i]\n",
    "            # Check Target (y)\n",
    "            if torch.isnan(data.y) or torch.isinf(data.y):\n",
    "                problematic_count += 1\n",
    "                continue\n",
    "            # Check Positions (pos)\n",
    "            if torch.isnan(data.pos).any() or torch.isinf(data.pos).any():\n",
    "                problematic_count += 1\n",
    "                continue\n",
    "            # Check Atomic Numbers (z) - must be between 1 and 118\n",
    "            if (data.z <= 0).any() or (data.z > 118).any():\n",
    "                problematic_count += 1\n",
    "                continue\n",
    "            clean_indices.append(i)\n",
    "        except Exception as e:\n",
    "            problematic_count += 1\n",
    "            if i < 10: \n",
    "                print(f\"Error at Index {i}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        if i % 10000 == 0:\n",
    "            print(f\"Processed: {i}/{len(dataset)}, Clean: {len(clean_indices)}, Problematic: {problematic_count}\")\n",
    "    \n",
    "    print(f\"Clean samples: {len(clean_indices)}\")\n",
    "    print(f\"Problematic samples: {problematic_count}\")\n",
    "    return clean_indices\n",
    "\n",
    "# Execute cleaning\n",
    "clean_indices = clean_dataset(dataset_with_target)\n",
    "\n",
    "# Create a clean Subset\n",
    "clean_dataset_obj = Subset(dataset_with_target, clean_indices)\n",
    "\n",
    "# Optimized DataLoader\n",
    "loader = DataLoader(\n",
    "    clean_dataset_obj, \n",
    "    batch_size=32, \n",
    "    shuffle=True, \n",
    "    num_workers=2, \n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "# 2. Target Statistics (for normalization context)\n",
    "all_y_values = []\n",
    "print(\"Collecting Y statistics...\")\n",
    "for i, idx in enumerate(clean_indices[:1000]):\n",
    "    try:\n",
    "        y_val = dataset_with_target[idx].y.item()\n",
    "        all_y_values.append(y_val)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "y_mean, y_std = np.mean(all_y_values), np.std(all_y_values)\n",
    "print(f\"Y Stats - Mean: {y_mean:.4f}, Std: {y_std:.4f}\")\n",
    "\n",
    "# 3. Model Definition - Scaled down for stability\n",
    "model = SchNet(\n",
    "    hidden_channels=64,\n",
    "    num_filters=64,\n",
    "    num_interactions=4,\n",
    "    num_gaussians=25,\n",
    "    cutoff=8.0,\n",
    "    readout=\"mean\" # Using 'mean' instead of 'add' for smoother gradients\n",
    ").to(device)\n",
    "\n",
    "# 4. Optimizer & Scheduler\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.5)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# 5. Training Loop\n",
    "print(\"Starting training...\")\n",
    "for epoch in range(5):\n",
    "    model.train()\n",
    "    total_loss, valid_batches = 0, 0\n",
    "    epoch_losses = []\n",
    "    \n",
    "    for batch_idx, batch in enumerate(loader):\n",
    "        try:\n",
    "            batch = batch.to(device)\n",
    "            if torch.isnan(batch.y).any(): continue\n",
    "                \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Prediction with squeeze to ensure 1D tensor\n",
    "            pred = model(batch.z, batch.pos, batch.batch).squeeze()\n",
    "            \n",
    "            # Dimension handling\n",
    "            if pred.dim() == 0: pred = pred.unsqueeze(0)\n",
    "            if len(pred) != len(batch.y): continue\n",
    "            \n",
    "            # Validation checks for stability\n",
    "            if torch.isnan(pred).any(): continue\n",
    "            \n",
    "            loss = loss_fn(pred, batch.y)\n",
    "            if torch.isnan(loss): continue\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping to prevent exploding gradients\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            epoch_losses.append(loss.item())\n",
    "            valid_batches += 1\n",
    "            \n",
    "            if batch_idx % 1000 == 0 and batch_idx > 0:\n",
    "                print(f\"Epoch {epoch+1}, Batch {batch_idx}: Avg Loss = {total_loss/valid_batches:.4f}\")\n",
    "            \n",
    "            # Optional: early break for quick testing\n",
    "            # if batch_idx > 5000: break\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Batch {batch_idx} Error: {str(e)[:50]}\")\n",
    "            continue\n",
    "    \n",
    "    # Epoch summary\n",
    "    if valid_batches > 0:\n",
    "        avg_loss = total_loss / valid_batches\n",
    "        scheduler.step(avg_loss)\n",
    "        print(f\"Epoch {epoch+1} Complete: Avg Loss: {avg_loss:.4f}, LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "\n",
    "# 6. Evaluation (Sample)\n",
    "print(\"\\nRunning Evaluation (First 1000 samples)...\")\n",
    "model.eval()\n",
    "test_subset = Subset(clean_dataset_obj, range(min(1000, len(clean_dataset_obj))))\n",
    "test_loader = DataLoader(test_subset, batch_size=32, shuffle=False)\n",
    "\n",
    "preds, actuals = [], []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        batch = batch.to(device)\n",
    "        pred = model(batch.z, batch.pos, batch.batch).squeeze()\n",
    "        if pred.dim() == 0: pred = pred.unsqueeze(0)\n",
    "        preds.extend(pred.cpu().numpy())\n",
    "        actuals.extend(batch.y.cpu().numpy())\n",
    "\n",
    "# Final Metrics\n",
    "mae = np.mean(np.abs(np.array(preds) - np.array(actuals)))\n",
    "correlation = np.corrcoef(preds, actuals)[0, 1]\n",
    "print(f\"Final MAE: {mae:.4f}\")\n",
    "print(f\"Correlation: {correlation:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-10T18:23:49.783376Z",
     "iopub.status.busy": "2025-08-10T18:23:49.782752Z",
     "iopub.status.idle": "2025-08-10T18:24:15.292537Z",
     "shell.execute_reply": "2025-08-10T18:24:15.291611Z",
     "shell.execute_reply.started": "2025-08-10T18:23:49.783351Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "# 1. Cleaning Problematic Data\n",
    "def clean_dataset(dataset):\n",
    "    \"\"\"Removes data points with NaN/Inf values or invalid atomic numbers.\"\"\"\n",
    "    clean_indices = []\n",
    "    problematic_count = 0\n",
    "    \n",
    "    print(\"Cleaning dataset...\")\n",
    "    for i in range(len(dataset)):\n",
    "        try:\n",
    "            data = dataset[i]\n",
    "            # Check Target (y)\n",
    "            if torch.isnan(data.y) or torch.isinf(data.y):\n",
    "                problematic_count += 1\n",
    "                continue\n",
    "            # Check Positions (pos)\n",
    "            if torch.isnan(data.pos).any() or torch.isinf(data.pos).any():\n",
    "                problematic_count += 1\n",
    "                continue\n",
    "            # Check Atomic Numbers (z) - must be between 1 and 118\n",
    "            if (data.z <= 0).any() or (data.z > 118).any():\n",
    "                problematic_count += 1\n",
    "                continue\n",
    "            clean_indices.append(i)\n",
    "        except Exception as e:\n",
    "            problematic_count += 1\n",
    "            if i < 10: \n",
    "                print(f\"Error at Index {i}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        if i % 10000 == 0:\n",
    "            print(f\"Processed: {i}/{len(dataset)}, Clean: {len(clean_indices)}, Problematic: {problematic_count}\")\n",
    "    \n",
    "    print(f\"Clean samples: {len(clean_indices)}\")\n",
    "    print(f\"Problematic samples: {problematic_count}\")\n",
    "    return clean_indices\n",
    "\n",
    "# Execute cleaning\n",
    "clean_indices = clean_dataset(dataset_with_target)\n",
    "\n",
    "# Create a clean Subset\n",
    "clean_dataset_obj = Subset(dataset_with_target, clean_indices)\n",
    "\n",
    "# Optimized DataLoader\n",
    "loader = DataLoader(\n",
    "    clean_dataset_obj, \n",
    "    batch_size=32, \n",
    "    shuffle=True, \n",
    "    num_workers=2, \n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "# 2. Target Statistics (for normalization context)\n",
    "all_y_values = []\n",
    "print(\"Collecting Y statistics...\")\n",
    "for i, idx in enumerate(clean_indices[:1000]):\n",
    "    try:\n",
    "        y_val = dataset_with_target[idx].y.item()\n",
    "        all_y_values.append(y_val)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "y_mean, y_std = np.mean(all_y_values), np.std(all_y_values)\n",
    "print(f\"Y Stats - Mean: {y_mean:.4f}, Std: {y_std:.4f}\")\n",
    "\n",
    "# 3. Model Definition - Scaled down for stability\n",
    "model = SchNet(\n",
    "    hidden_channels=64,\n",
    "    num_filters=64,\n",
    "    num_interactions=4,\n",
    "    num_gaussians=25,\n",
    "    cutoff=8.0,\n",
    "    readout=\"mean\" # Using 'mean' instead of 'add' for smoother gradients\n",
    ").to(device)\n",
    "\n",
    "# 4. Optimizer & Scheduler\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.5)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# 5. Training Loop\n",
    "print(\"Starting training...\")\n",
    "for epoch in range(5):\n",
    "    model.train()\n",
    "    total_loss, valid_batches = 0, 0\n",
    "    epoch_losses = []\n",
    "    \n",
    "    for batch_idx, batch in enumerate(loader):\n",
    "        try:\n",
    "            batch = batch.to(device)\n",
    "            if torch.isnan(batch.y).any(): continue\n",
    "                \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Prediction with squeeze to ensure 1D tensor\n",
    "            pred = model(batch.z, batch.pos, batch.batch).squeeze()\n",
    "            \n",
    "            # Dimension handling\n",
    "            if pred.dim() == 0: pred = pred.unsqueeze(0)\n",
    "            if len(pred) != len(batch.y): continue\n",
    "            \n",
    "            # Validation checks for stability\n",
    "            if torch.isnan(pred).any(): continue\n",
    "            \n",
    "            loss = loss_fn(pred, batch.y)\n",
    "            if torch.isnan(loss): continue\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping to prevent exploding gradients\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            epoch_losses.append(loss.item())\n",
    "            valid_batches += 1\n",
    "            \n",
    "            if batch_idx % 1000 == 0 and batch_idx > 0:\n",
    "                print(f\"Epoch {epoch+1}, Batch {batch_idx}: Avg Loss = {total_loss/valid_batches:.4f}\")\n",
    "            \n",
    "            # Optional: early break for quick testing\n",
    "            # if batch_idx > 5000: break\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Batch {batch_idx} Error: {str(e)[:50]}\")\n",
    "            continue\n",
    "    \n",
    "    # Epoch summary\n",
    "    if valid_batches > 0:\n",
    "        avg_loss = total_loss / valid_batches\n",
    "        scheduler.step(avg_loss)\n",
    "        print(f\"Epoch {epoch+1} Complete: Avg Loss: {avg_loss:.4f}, LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "\n",
    "# 6. Evaluation (Sample)\n",
    "print(\"\\nRunning Evaluation (First 1000 samples)...\")\n",
    "model.eval()\n",
    "test_subset = Subset(clean_dataset_obj, range(min(1000, len(clean_dataset_obj))))\n",
    "test_loader = DataLoader(test_subset, batch_size=32, shuffle=False)\n",
    "\n",
    "preds, actuals = [], []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        batch = batch.to(device)\n",
    "        pred = model(batch.z, batch.pos, batch.batch).squeeze()\n",
    "        if pred.dim() == 0: pred = pred.unsqueeze(0)\n",
    "        preds.extend(pred.cpu().numpy())\n",
    "        actuals.extend(batch.y.cpu().numpy())\n",
    "\n",
    "# Final Metrics\n",
    "mae = np.mean(np.abs(np.array(preds) - np.array(actuals)))\n",
    "correlation = np.corrcoef(preds, actuals)[0, 1]\n",
    "print(f\"Final MAE: {mae:.4f}\")\n",
    "print(f\"Correlation: {correlation:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8034853,
     "sourceId": 12712639,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8034868,
     "sourceId": 12712662,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8044374,
     "sourceId": 12727059,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
