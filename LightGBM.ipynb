{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9925b492-0d7a-4637-86c6-5094a09faad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import warnings, joblib, pandas as pd\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import lightgbm as lgb\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# --- Data Loading and Feature Selection ---\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "# Remove non-feature columns\n",
    "df = df.drop(columns=[c for c in ID_COLS if c in df.columns], errors=\"ignore\")\n",
    "\n",
    "y_all = df[TARGET].astype(float)\n",
    "X_all = df.drop(columns=[TARGET]).select_dtypes(include=\"number\")\n",
    "# Replace infinite values and drop missing data\n",
    "X_all = X_all.replace([float(\"inf\"), -float(\"inf\")], pd.NA).dropna()\n",
    "\n",
    "# --- Loading Predefined Index Splits ---\n",
    "idx_tr = pd.read_csv(\"split_train.csv\")[\"idx\"].values\n",
    "idx_va = pd.read_csv(\"split_val.csv\")[\"idx\"].values\n",
    "idx_te = pd.read_csv(\"split_test.csv\")[\"idx\"].values\n",
    "\n",
    "# Creating training, validation, and test sets based on indices\n",
    "X_train, y_train = X_all.iloc[idx_tr], y_all.iloc[idx_tr]\n",
    "X_val,   y_val   = X_all.iloc[idx_va], y_all.iloc[idx_va]\n",
    "X_test,  y_test  = X_all.iloc[idx_te], y_all.iloc[idx_te]\n",
    "\n",
    "# --- Model Configuration ---\n",
    "params = {\n",
    "    \"n_estimators\": 1586,\n",
    "    \"learning_rate\": 0.06213190804903206,\n",
    "    \"num_leaves\": 147,\n",
    "    \"max_depth\": -1,\n",
    "    \"min_child_samples\": 90,\n",
    "    \"min_sum_hessian_in_leaf\": 0.276379400698885,\n",
    "    \"feature_fraction\": 0.833584461172753,\n",
    "    \"bagging_fraction\": 0.7878386380407747,\n",
    "    \"bagging_freq\": 2,\n",
    "    \"lambda_l1\": 12.634781942523427,\n",
    "    \"lambda_l2\": 28.826312926864468,\n",
    "    \"min_gain_to_split\": 0.0008122876817837996,\n",
    "    \"boosting_type\": \"dart\",\n",
    "    \"objective\": \"regression\",\n",
    "    \"metric\": \"l2\",\n",
    "    \"verbosity\": -1,\n",
    "    \"random_state\": RANDOM_STATE,\n",
    "    \"n_jobs\": -1\n",
    "}\n",
    "\n",
    "# --- Model Training ---\n",
    "model = lgb.LGBMRegressor(**params)\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    eval_metric=\"l2\",\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(ES, verbose=False), \n",
    "        lgb.log_evaluation(0)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# --- Performance Evaluation ---\n",
    "def print_metrics(set_name, y_true, y_pred):\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    print(f\"{set_name:5} -> RÂ²: {r2:.6f} | MAE: {mae:.6f} | MSE: {mse:.6f}\")\n",
    "\n",
    "print_metrics(\"Train\", y_train, model.predict(X_train))\n",
    "print_metrics(\"Val\",   y_val,   model.predict(X_val))\n",
    "print_metrics(\"Test\",  y_test,  model.predict(X_test))\n",
    "\n",
    "# --- Model Persistence ---\n",
    "joblib.dump(model, \"lightgbm_model.pkl\")\n",
    "print(\"Model successfully saved: lightgbm_model.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py31016",
   "language": "python",
   "name": "py31016"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
