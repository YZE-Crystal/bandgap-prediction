{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8567fa-088d-4471-b90f-d505ca86c093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os, warnings, joblib, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "# Environmental configuration to prevent threading conflicts in notebooks\n",
    "os.environ.setdefault(\"OMP_NUM_THREADS\", \"1\")\n",
    "os.environ.setdefault(\"OPENBLAS_NUM_THREADS\", \"1\")\n",
    "os.environ.setdefault(\"MKL_NUM_THREADS\", \"1\")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ================== Paths & Configuration ==================\n",
    "CSV_PATH = \"9_makale_data_guncel.csv\"\n",
    "TARGET   = \"band_gap\"\n",
    "ID_COLS  = [\"material_id\", \"formula_pretty\"]\n",
    "\n",
    "# Model Filenames\n",
    "PATH_CAT  = \"catboost.cbm\"\n",
    "PATH_LGB  = \"lightgbm_model.pkl\"\n",
    "PATH_XGB  = \"xgb_model.pkl\"\n",
    "PATH_RF   = \"rf_model.joblib\"\n",
    "PATH_MLP  = \"mlp_trained.joblib\"\n",
    "PATH_SCLR = \"mlp_scaler.joblib\"\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# ================== Utility Functions ==================\n",
    "def report(tag, y_true, y_pred):\n",
    "    \"\"\"Calculates and prints regression performance metrics.\"\"\"\n",
    "    r2  = r2_score(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    print(f\"{tag:>10} -> R²={r2:.6f} | MAE={mae:.6f} | MSE={mse:.6f}\")\n",
    "\n",
    "# ================== Data Preprocessing ==================\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "df = df.drop(columns=[c for c in ID_COLS if c in df.columns], errors=\"ignore\")\n",
    "y  = df[TARGET].astype(float)\n",
    "X  = df.drop(columns=[TARGET]).select_dtypes(include=[np.number]).copy()\n",
    "\n",
    "# Stratified Splitting (70/15/15)\n",
    "# Using quantiles to ensure balanced distribution of band gaps in all sets\n",
    "y_bins = pd.qcut(y, q=10, duplicates=\"drop\", labels=False)\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "    X, y, test_size=0.15, shuffle=True, random_state=RANDOM_STATE, stratify=y_bins\n",
    ")\n",
    "\n",
    "y_bins_tv = pd.qcut(y_trainval, q=10, duplicates=\"drop\", labels=False)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_trainval, y_trainval, test_size=0.17647, shuffle=True, \n",
    "    random_state=RANDOM_STATE, stratify=y_bins_tv\n",
    ")\n",
    "\n",
    "# ================== Model Loading ==================\n",
    "base_models = {}\n",
    "\n",
    "# Load available models with error handling\n",
    "try:\n",
    "    from catboost import CatBoostRegressor, Pool\n",
    "    if os.path.exists(PATH_CAT):\n",
    "        cat = CatBoostRegressor()\n",
    "        cat.load_model(PATH_CAT)\n",
    "        base_models[\"catboost\"] = cat\n",
    "except: pass\n",
    "\n",
    "if os.path.exists(PATH_LGB): base_models[\"lightgbm\"] = joblib.load(PATH_LGB)\n",
    "if os.path.exists(PATH_XGB): base_models[\"xgboost\"] = joblib.load(PATH_XGB)\n",
    "if os.path.exists(PATH_RF):  base_models[\"random_forest\"] = joblib.load(PATH_RF)\n",
    "\n",
    "# MLP requires its specific scaler\n",
    "if os.path.exists(PATH_MLP) and os.path.exists(PATH_SCLR):\n",
    "    base_models[\"mlp\"] = (joblib.load(PATH_MLP), joblib.load(PATH_SCLR))\n",
    "\n",
    "print(f\"Active Models: {list(base_models.keys())}\")\n",
    "\n",
    "# ================== Stacking Process ==================\n",
    "\n",
    "\n",
    "\n",
    "def try_predict_one(name, X_df):\n",
    "    \"\"\"Wrapper to handle model-specific prediction logic.\"\"\"\n",
    "    try:\n",
    "        if name == \"catboost\":\n",
    "            X_cat = X_df.copy()\n",
    "            X_cat.columns = [c.replace(\" \", \"_\") for c in X_cat.columns]\n",
    "            return base_models[name].predict(Pool(X_cat)).ravel()\n",
    "        elif name == \"mlp\":\n",
    "            m, s = base_models[name]\n",
    "            return m.predict(s.transform(X_df)).ravel()\n",
    "        else:\n",
    "            return base_models[name].predict(X_df).ravel()\n",
    "    except Exception as e:\n",
    "        print(f\"Error predicting with {name}: {e}\")\n",
    "        return None\n",
    "\n",
    "def generate_meta_features(X_df, model_names):\n",
    "    \"\"\"Stacks predictions into a feature matrix for the meta-learner.\"\"\"\n",
    "    preds = {name: try_predict_one(name, X_df) for name in model_names}\n",
    "    return pd.DataFrame({k: v for k, v in preds.items() if v is not None}, index=X_df.index)\n",
    "\n",
    "# Generate predictions for Meta-Learner training (Validation set) and Final testing\n",
    "Z_val  = generate_meta_features(X_val, base_models.keys())\n",
    "Z_test = generate_meta_features(X_test, base_models.keys())\n",
    "\n",
    "# Meta-Learner: Ridge Regression with Built-in Cross-Validation for Alpha\n",
    "\n",
    "meta_learner = RidgeCV(alphas=np.logspace(-6, 3, 30))\n",
    "meta_learner.fit(Z_val, y_val)\n",
    "\n",
    "# Final Performance Results\n",
    "print(\"\\n=== FINAL ENSEMBLE RESULTS ===\")\n",
    "report(\"Validation\", y_val, meta_learner.predict(Z_val))\n",
    "report(\"Test\", y_test, meta_learner.predict(Z_test))\n",
    "\n",
    "# Weight Analysis\n",
    "weights = pd.Series(meta_learner.coef_, index=Z_val.columns).sort_values(ascending=False)\n",
    "print(\"\\nModel Weights in Ensemble:\")\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd166e4c-6177-40a0-89c1-7ae3d7fb45ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os, warnings, joblib, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "# Environmental configuration to prevent threading conflicts in notebooks\n",
    "os.environ.setdefault(\"OMP_NUM_THREADS\", \"1\")\n",
    "os.environ.setdefault(\"OPENBLAS_NUM_THREADS\", \"1\")\n",
    "os.environ.setdefault(\"MKL_NUM_THREADS\", \"1\")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ================== Paths & Configuration ==================\n",
    "CSV_PATH = \"9_makale_data_guncel.csv\"\n",
    "TARGET   = \"band_gap\"\n",
    "ID_COLS  = [\"material_id\", \"formula_pretty\"]\n",
    "\n",
    "# Model Filenames\n",
    "PATH_CAT  = \"catboost.cbm\"\n",
    "PATH_LGB  = \"lightgbm_model.pkl\"\n",
    "PATH_XGB  = \"xgb_model.pkl\"\n",
    "PATH_RF   = \"rf_model.joblib\"\n",
    "PATH_MLP  = \"mlp_trained.joblib\"\n",
    "PATH_SCLR = \"mlp_scaler.joblib\"\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# ================== Utility Functions ==================\n",
    "def report(tag, y_true, y_pred):\n",
    "    \"\"\"Calculates and prints regression performance metrics.\"\"\"\n",
    "    r2  = r2_score(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    print(f\"{tag:>10} -> R²={r2:.6f} | MAE={mae:.6f} | MSE={mse:.6f}\")\n",
    "\n",
    "# ================== Data Preprocessing ==================\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "df = df.drop(columns=[c for c in ID_COLS if c in df.columns], errors=\"ignore\")\n",
    "y  = df[TARGET].astype(float)\n",
    "X  = df.drop(columns=[TARGET]).select_dtypes(include=[np.number]).copy()\n",
    "\n",
    "# Stratified Splitting (70/15/15)\n",
    "# Using quantiles to ensure balanced distribution of band gaps in all sets\n",
    "y_bins = pd.qcut(y, q=10, duplicates=\"drop\", labels=False)\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "    X, y, test_size=0.15, shuffle=True, random_state=RANDOM_STATE, stratify=y_bins\n",
    ")\n",
    "\n",
    "y_bins_tv = pd.qcut(y_trainval, q=10, duplicates=\"drop\", labels=False)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_trainval, y_trainval, test_size=0.17647, shuffle=True, \n",
    "    random_state=RANDOM_STATE, stratify=y_bins_tv\n",
    ")\n",
    "\n",
    "# ================== Model Loading ==================\n",
    "base_models = {}\n",
    "\n",
    "# Load available models with error handling\n",
    "try:\n",
    "    from catboost import CatBoostRegressor, Pool\n",
    "    if os.path.exists(PATH_CAT):\n",
    "        cat = CatBoostRegressor()\n",
    "        cat.load_model(PATH_CAT)\n",
    "        base_models[\"catboost\"] = cat\n",
    "except: pass\n",
    "\n",
    "if os.path.exists(PATH_LGB): base_models[\"lightgbm\"] = joblib.load(PATH_LGB)\n",
    "if os.path.exists(PATH_XGB): base_models[\"xgboost\"] = joblib.load(PATH_XGB)\n",
    "if os.path.exists(PATH_RF):  base_models[\"random_forest\"] = joblib.load(PATH_RF)\n",
    "\n",
    "# MLP requires its specific scaler\n",
    "if os.path.exists(PATH_MLP) and os.path.exists(PATH_SCLR):\n",
    "    base_models[\"mlp\"] = (joblib.load(PATH_MLP), joblib.load(PATH_SCLR))\n",
    "\n",
    "print(f\"Active Models: {list(base_models.keys())}\")\n",
    "\n",
    "# ================== Stacking Process ==================\n",
    "\n",
    "\n",
    "\n",
    "def try_predict_one(name, X_df):\n",
    "    \"\"\"Wrapper to handle model-specific prediction logic.\"\"\"\n",
    "    try:\n",
    "        if name == \"catboost\":\n",
    "            X_cat = X_df.copy()\n",
    "            X_cat.columns = [c.replace(\" \", \"_\") for c in X_cat.columns]\n",
    "            return base_models[name].predict(Pool(X_cat)).ravel()\n",
    "        elif name == \"mlp\":\n",
    "            m, s = base_models[name]\n",
    "            return m.predict(s.transform(X_df)).ravel()\n",
    "        else:\n",
    "            return base_models[name].predict(X_df).ravel()\n",
    "    except Exception as e:\n",
    "        print(f\"Error predicting with {name}: {e}\")\n",
    "        return None\n",
    "\n",
    "def generate_meta_features(X_df, model_names):\n",
    "    \"\"\"Stacks predictions into a feature matrix for the meta-learner.\"\"\"\n",
    "    preds = {name: try_predict_one(name, X_df) for name in model_names}\n",
    "    return pd.DataFrame({k: v for k, v in preds.items() if v is not None}, index=X_df.index)\n",
    "\n",
    "# Generate predictions for Meta-Learner training (Validation set) and Final testing\n",
    "Z_val  = generate_meta_features(X_val, base_models.keys())\n",
    "Z_test = generate_meta_features(X_test, base_models.keys())\n",
    "\n",
    "# Meta-Learner: Ridge Regression with Built-in Cross-Validation for Alpha\n",
    "\n",
    "meta_learner = RidgeCV(alphas=np.logspace(-6, 3, 30))\n",
    "meta_learner.fit(Z_val, y_val)\n",
    "\n",
    "# Final Performance Results\n",
    "print(\"\\n=== FINAL ENSEMBLE RESULTS ===\")\n",
    "report(\"Validation\", y_val, meta_learner.predict(Z_val))\n",
    "report(\"Test\", y_test, meta_learner.predict(Z_test))\n",
    "\n",
    "# Weight Analysis\n",
    "weights = pd.Series(meta_learner.coef_, index=Z_val.columns).sort_values(ascending=False)\n",
    "print(\"\\nModel Weights in Ensemble:\")\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff92f5c6-609a-4800-8fbc-fa697199fa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os, warnings, joblib, pickle, numpy as np, pandas as pd\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from itertools import combinations\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# --- Paths & Configuration ---\n",
    "CSV_PATH = \"9_makale_data_guncel.csv\"\n",
    "TARGET = \"band_gap\"\n",
    "ID_COLS = [\"material_id\", \"formula_pretty\"]\n",
    "\n",
    "PATH_CAT = \"catboost.cbm\"\n",
    "PATH_LGB = \"lightgbm_model.pkl\"\n",
    "PATH_XGB = \"xgb_model.pkl\"\n",
    "PATH_RF  = \"rf_model.joblib\"\n",
    "PATH_MLP = \"mlp_artifacts/mlp_trained.joblib\"\n",
    "PATH_SCLR = \"mlp_artifacts/mlp_scaler.joblib\"\n",
    "\n",
    "# ================== XGBoost Wrapper ==================\n",
    "import xgboost as xgb\n",
    "class XGBSklearnWrapper:\n",
    "    \"\"\"Standardizes XGBoost prediction calls for Sklearn compatibility.\"\"\"\n",
    "    def __init__(self, booster, feature_names):\n",
    "        self.booster = booster\n",
    "        self.feature_names_ = list(feature_names)\n",
    "    def predict(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X[self.feature_names_]\n",
    "        dm = xgb.DMatrix(X)\n",
    "        return self.booster.predict(dm, iteration_range=(0, self.booster.best_iteration + 1))\n",
    "\n",
    "# ================== Data Loading ==================\n",
    "df = pd.read_csv(CSV_PATH).drop(columns=[c for c in ID_COLS if c in df.columns], errors=\"ignore\")\n",
    "y_all = df[TARGET].astype(float)\n",
    "X_all = df.drop(columns=[TARGET]).select_dtypes(include=\"number\").copy()\n",
    "\n",
    "# Load predefined splits\n",
    "idx_tr = pd.read_csv(\"split_train.csv\")[\"idx\"].values\n",
    "idx_va = pd.read_csv(\"split_val.csv\")[\"idx\"].values\n",
    "idx_te = pd.read_csv(\"split_test.csv\")[\"idx\"].values\n",
    "\n",
    "X_train, y_train = X_all.iloc[idx_tr], y_all.iloc[idx_tr]\n",
    "X_val,   y_val   = X_all.iloc[idx_va], y_all.iloc[idx_va]\n",
    "X_test,  y_test  = X_all.iloc[idx_te], y_all.iloc[idx_te]\n",
    "\n",
    "print(f\"Dataset Split: Train={len(idx_tr)} | Val={len(idx_va)} | Test={len(idx_te)}\")\n",
    "\n",
    "# ================== Loading Base Models ==================\n",
    "base_models = {}\n",
    "\n",
    "# CatBoost\n",
    "try:\n",
    "    from catboost import CatBoostRegressor, Pool\n",
    "    if os.path.exists(PATH_CAT):\n",
    "        m = CatBoostRegressor(); m.load_model(PATH_CAT); base_models[\"catboost\"] = m\n",
    "except Exception as e:\n",
    "    print(\"[catboost] Error loading:\", e)\n",
    "\n",
    "# LightGBM / RF\n",
    "if os.path.exists(PATH_LGB): base_models[\"lightgbm\"] = joblib.load(PATH_LGB)\n",
    "if os.path.exists(PATH_RF):  base_models[\"random_forest\"] = joblib.load(PATH_RF)\n",
    "\n",
    "# XGBoost\n",
    "if os.path.exists(PATH_XGB):\n",
    "    try:\n",
    "        with open(PATH_XGB, \"rb\") as f: base_models[\"xgboost\"] = pickle.load(f)\n",
    "    except Exception as e:\n",
    "        print(\"[xgboost] Error loading:\", e)\n",
    "\n",
    "# MLP\n",
    "mlp_scaler = joblib.load(PATH_SCLR) if os.path.exists(PATH_SCLR) else None\n",
    "mlp_model  = joblib.load(PATH_MLP)  if os.path.exists(PATH_MLP)  else None\n",
    "if mlp_model is not None and mlp_scaler is not None:\n",
    "    base_models[\"mlp\"] = (mlp_model, mlp_scaler)\n",
    "\n",
    "if not base_models: raise RuntimeError(\"No base models found.\")\n",
    "print(\"Loaded models:\", list(base_models.keys()))\n",
    "\n",
    "# ================== Prediction Helper ==================\n",
    "def try_predict(name, X):\n",
    "    \"\"\"Handles model-specific input formatting for predictions.\"\"\"\n",
    "    try:\n",
    "        if name == \"catboost\":\n",
    "            X_cat = X.copy()\n",
    "            X_cat.columns = [c.replace(\" \", \"_\") for c in X_cat.columns]\n",
    "            return np.asarray(base_models[\"catboost\"].predict(Pool(X_cat))).ravel()\n",
    "        elif name == \"mlp\":\n",
    "            mlp, scaler = base_models[\"mlp\"]\n",
    "            return np.asarray(mlp.predict(scaler.transform(X))).ravel()\n",
    "        else:\n",
    "            return np.asarray(base_models[name].predict(X)).ravel()\n",
    "    except Exception as e:\n",
    "        print(f\"[{name}] Prediction failed: {e}\")\n",
    "        return None\n",
    "\n",
    "# ================== Active Models Check ==================\n",
    "active = []\n",
    "for n in list(base_models.keys()):\n",
    "    p = try_predict(n, X_val.head(256))\n",
    "    if p is not None and np.isfinite(p).all(): active.append(n)\n",
    "print(\"Active models available for testing:\", active)\n",
    "\n",
    "# ================== Meta-Feature Matrix Helper ==================\n",
    "def preds_matrix(X, names):\n",
    "    \"\"\"Stacks predictions to create meta-features.\"\"\"\n",
    "    cols, arr = [], []\n",
    "    for n in names:\n",
    "        p = try_predict(n, X)\n",
    "        if p is not None: cols.append(n); arr.append(p)\n",
    "    return pd.DataFrame(np.vstack(arr).T, columns=cols, index=X.index)\n",
    "\n",
    "# ================== Combinatorial Search ==================\n",
    "best_combo = None\n",
    "best_r2 = -1\n",
    "results = []\n",
    "\n",
    "print(\"\\nStarting combination search...\")\n",
    "for r in range(1, len(active) + 1):\n",
    "    for combo in combinations(active, r):\n",
    "        # Generate meta-features for the current subset\n",
    "        Z_val  = preds_matrix(X_val,  combo)\n",
    "        Z_test = preds_matrix(X_test, combo)\n",
    "\n",
    "        # Fit Ridge meta-learner on validation predictions\n",
    "        meta = RidgeCV(alphas=np.logspace(-6, 3, 30))\n",
    "        meta.fit(Z_val, y_val)\n",
    "\n",
    "        # Evaluate on test predictions\n",
    "        y_pred_test = meta.predict(Z_test)\n",
    "        r2 = r2_score(y_test, y_pred_test)\n",
    "\n",
    "        results.append((combo, r2))\n",
    "        print(f\"Combo {combo} -> Test R²: {r2:.6f}\")\n",
    "\n",
    "        if r2 > best_r2:\n",
    "            best_r2 = r2\n",
    "            best_combo = combo\n",
    "\n",
    "print(\"\\n=== OPTIMIZATION SUMMARY ===\")\n",
    "print(f\"Best Combination Found: {best_combo}\")\n",
    "print(f\"Best Test R² Achieved: {best_r2:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f4ee07-18ec-470b-859d-4fecf2a49be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================== Final Predictions with Best Combination ==================\n",
    "print(\"\\n=== FINAL PREDICTIONS & ANALYSIS ===\")\n",
    "\n",
    "# Generate meta-features using the best combination of models identified previously\n",
    "Z_val  = preds_matrix(X_val,  best_combo)\n",
    "Z_test = preds_matrix(X_test, best_combo)\n",
    "\n",
    "# Final Meta-Learner (RidgeCV) fit on the validation predictions\n",
    "meta = RidgeCV(alphas=np.logspace(-6, 3, 30))\n",
    "meta.fit(Z_val, y_val)\n",
    "\n",
    "# Predict for both sets\n",
    "y_pred_val  = meta.predict(Z_val)\n",
    "y_pred_test = meta.predict(Z_test)\n",
    "\n",
    "# ================== Comprehensive Error Analysis ==================\n",
    "import numpy as np\n",
    "\n",
    "# Absolute errors for the validation set\n",
    "errors = np.abs(y_val - y_pred_val)\n",
    "\n",
    "# 1) Success Rate by Error Thresholds\n",
    "print(\"\\n--- Success Rate by Error Thresholds ---\")\n",
    "thresholds = [0.25, 0.5, 1.0] # error in eV\n",
    "for t in thresholds:\n",
    "    percentage = np.mean(errors < t) * 100\n",
    "    print(f\"{percentage:.2f}% of model predictions have an error below {t} eV.\")\n",
    "\n",
    "# 2) Percentile-Based Error Distribution\n",
    "print(\"\\n--- Percentile-Based Error Distribution ---\")\n",
    "for p in [50, 75, 90]:\n",
    "    th = np.percentile(errors, p)\n",
    "    print(f\"{p}% of predictions have an error below {th:.3f} eV.\")\n",
    "\n",
    "# 3) Analysis for a Specific Range (Example: 5.5–6.0 eV)\n",
    "print(\"\\n--- Range Analysis (5.5–6.0 eV) ---\")\n",
    "mask = (y_pred_val >= 5.5) & (y_pred_val <= 6.0)\n",
    "subset_errors = np.abs(y_val[mask] - y_pred_val[mask])\n",
    "\n",
    "if len(subset_errors) > 0:\n",
    "    print(f\"Total number of predictions in this range: {len(subset_errors)}\")\n",
    "    for p in [50, 75, 90]:\n",
    "        th = np.percentile(subset_errors, p)\n",
    "        print(f\"{p}% of predictions in this range have an error below {th:.3f} eV.\")\n",
    "else:\n",
    "    print(\"No predictions found in this specific range.\")\n",
    "\n",
    "# 4) Signed Error Breakdown (Bias Detection in 0–4 eV range)\n",
    "print(\"\\n--- Signed Error Report (0–4 eV Range) ---\")\n",
    "def error_analysis(y_true, y_pred, min_val=0, max_val=4):\n",
    "    \"\"\"Calculates directional bias (over vs. under prediction).\"\"\"\n",
    "    mask = (y_pred >= min_val) & (y_pred <= max_val)\n",
    "    y_true_sub = y_true[mask]\n",
    "    y_pred_sub = y_pred[mask]\n",
    "    diffs = y_pred_sub - y_true_sub # Positive = Over-predicting, Negative = Under-predicting\n",
    "\n",
    "    pos_mask = diffs > 0\n",
    "    neg_mask = diffs < 0\n",
    "\n",
    "    return {\n",
    "        \"total_predictions\": len(diffs),\n",
    "        \"positive_count\": np.sum(pos_mask),\n",
    "        \"negative_count\": np.sum(neg_mask),\n",
    "        \"positive_mean_error\": np.mean(diffs[pos_mask]) if np.any(pos_mask) else 0,\n",
    "        \"negative_mean_error\": np.mean(diffs[neg_mask]) if np.any(neg_mask) else 0,\n",
    "        \"overall_mean_error\": np.mean(diffs) if len(diffs) > 0 else 0,\n",
    "    }\n",
    "\n",
    "report = error_analysis(y_val, y_pred_val, 0, 4)\n",
    "for key, value in report.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e769c5-b079-4c68-8ea3-48d29523d5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================== Final Prediction with Best Combination ==================\n",
    "print(\"\\n=== FINAL PREDICTIONS & ANALYSIS ===\")\n",
    "\n",
    "# Create meta-feature matrices using the optimal model subset\n",
    "Z_val  = preds_matrix(X_val,  best_combo)\n",
    "Z_test = preds_matrix(X_test, best_combo)\n",
    "\n",
    "# Final Meta-Learner (RidgeCV) trained on validation predictions\n",
    "meta = RidgeCV(alphas=np.logspace(-6, 3, 30))\n",
    "meta.fit(Z_val, y_val)\n",
    "\n",
    "# Generate final predictions\n",
    "y_pred_val  = meta.predict(Z_val)\n",
    "y_pred_test = meta.predict(Z_test)\n",
    "\n",
    "# ================== Error Analysis ==================\n",
    "import numpy as np\n",
    "\n",
    "# Absolute error calculation for the validation set\n",
    "errors = np.abs(y_val - y_pred_val)\n",
    "\n",
    "# 1) Success Rate based on Error Thresholds\n",
    "print(\"\\n--- Success Rate by Error Thresholds ---\")\n",
    "thresholds = [0.25, 0.5, 1.0] # error values in eV\n",
    "for t in thresholds:\n",
    "    percentage = np.mean(errors < t) * 100\n",
    "    print(f\"{percentage:.2f}% of predictions have an error below {t} eV.\")\n",
    "\n",
    "# 2) Percentile-Based Error Distribution\n",
    "# Useful for understanding the typical error magnitude (MAE is just the average)\n",
    "print(\"\\n--- Percentile-Based Error Distribution ---\")\n",
    "for p in [50, 75, 90]:\n",
    "    th = np.percentile(errors, p)\n",
    "    print(f\"{p}% of predictions have an error below {th:.3f} eV.\")\n",
    "    \n",
    "# 3) Range-Specific Analysis Function\n",
    "def range_analysis(y_true, y_pred, low, high):\n",
    "    \"\"\"Analyzes model performance within a specific band gap window.\"\"\"\n",
    "    print(f\"\\n--- {low}–{high} eV Range Analysis ---\")\n",
    "    mask = (y_pred >= low) & (y_pred <= high)\n",
    "    subset_errors = np.abs(y_true[mask] - y_pred[mask])\n",
    "    \n",
    "    print(f\"Total predictions in this range: {len(subset_errors)}\")\n",
    "    if len(subset_errors) > 0:\n",
    "        for p in [50, 75, 90]:\n",
    "            th = np.percentile(subset_errors, p)\n",
    "            print(f\"{p}% of predictions in this range have an error below {th:.3f} eV.\")\n",
    "    else:\n",
    "        print(\"No predictions found within this range.\")\n",
    "\n",
    "# Deep analysis for high-gap insulators (4.5–6.0 eV)\n",
    "range_analysis(y_val, y_pred_val, 4.5, 6.0)\n",
    "\n",
    "# Deep analysis for metals and semiconductors (0.0–4.5 eV)\n",
    "range_analysis(y_val, y_pred_val, 0.0, 4.5)\n",
    "\n",
    "# 4) Signed Error Analysis (Bias Detection in 0–4 eV range)\n",
    "print(\"\\n--- Signed Error Report (0–4 eV Range) ---\")\n",
    "def bias_analysis(y_true, y_pred, min_val=0, max_val=4):\n",
    "    \"\"\"Identifies if the model systematically over-predicts or under-predicts.\"\"\"\n",
    "    mask = (y_pred >= min_val) & (y_pred <= max_val)\n",
    "    y_true_sub = y_true[mask]\n",
    "    y_pred_sub = y_pred[mask]\n",
    "    \n",
    "    # Positive result means over-prediction, negative means under-prediction\n",
    "    diffs = y_pred_sub - y_true_sub\n",
    "\n",
    "    pos_mask = diffs > 0\n",
    "    neg_mask = diffs < 0\n",
    "\n",
    "    return {\n",
    "        \"total_predictions\": len(diffs),\n",
    "        \"over_prediction_count\": np.sum(pos_mask),\n",
    "        \"under_prediction_count\": np.sum(neg_mask),\n",
    "        \"mean_over_prediction_error\": np.mean(diffs[pos_mask]) if np.any(pos_mask) else 0,\n",
    "        \"mean_under_prediction_error\": np.mean(diffs[neg_mask]) if np.any(neg_mask) else 0,\n",
    "        \"overall_bias\": np.mean(diffs) if len(diffs) > 0 else 0,\n",
    "    }\n",
    "\n",
    "report = bias_analysis(y_val, y_pred_val, 0, 4)\n",
    "for key, value in report.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf4ef40-0449-46c7-83be-061ac45d899b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "def interval_error_analysis(y_true, y_pred, intervals):\n",
    "    \"\"\"Calculates MAE and RMSE for specific prediction ranges.\"\"\"\n",
    "    results = []\n",
    "    for low, high in intervals:\n",
    "        # Filter data points within the current interval\n",
    "        mask = (y_pred >= low) & (y_pred < high)\n",
    "        y_t, y_p = y_true[mask], y_pred[mask]\n",
    "        \n",
    "        if len(y_t) > 0:\n",
    "            mae  = mean_absolute_error(y_t, y_p)\n",
    "            mse  = mean_squared_error(y_t, y_p)\n",
    "            rmse = np.sqrt(mse)\n",
    "            results.append({\n",
    "                \"Interval\": f\"{low}–{high} eV\",\n",
    "                \"Count\": len(y_t),\n",
    "                \"MAE\": mae,\n",
    "                \"RMSE\": rmse\n",
    "            })\n",
    "        else:\n",
    "            results.append({\n",
    "                \"Interval\": f\"{low}–{high} eV\",\n",
    "                \"Count\": 0,\n",
    "                \"MAE\": None,\n",
    "                \"RMSE\": None\n",
    "            })\n",
    "    return results\n",
    "\n",
    "# Define custom intervals (e.g., metals/semiconductors vs. insulators)\n",
    "test_intervals = [(0, 2), (2, 4), (0, 4.5), (4.5, 6)]\n",
    "\n",
    "# Execute analysis on validation set\n",
    "analysis_data = interval_error_analysis(y_val, y_pred_val, test_intervals)\n",
    "\n",
    "# Display results as a DataFrame\n",
    "df_results = pd.DataFrame(analysis_data)\n",
    "print(df_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
